"""
========================================
å‘é‡æ£€ç´¢å™¨ (Milvus)
========================================

ğŸ“š æ¨¡å—è¯´æ˜ï¼š
- åŸºäºMilvusçš„å‘é‡æ£€ç´¢
- è¯­ä¹‰ç›¸ä¼¼åº¦æœç´¢
- æ”¯æŒåˆ†å±‚å­˜å‚¨

ğŸ¯ æ ¸å¿ƒåŠŸèƒ½ï¼š
1. å‘é‡ç´¢å¼•æ„å»º
2. è¯­ä¹‰æ£€ç´¢
3. æ··åˆè¿‡æ»¤
4. æ‰¹é‡æ£€ç´¢

========================================
"""

from typing import List, Dict, Optional, Tuple
import numpy as np

from pymilvus import (
    connections,
    Collection,
    CollectionSchema,
    FieldSchema,
    DataType,
    utility
)
from loguru import logger

from services.embedding.embedder import Embedder


class VectorRetriever:
    """
    å‘é‡æ£€ç´¢å™¨ï¼ˆåŸºäºMilvusï¼‰

    ğŸ”§ æŠ€æœ¯ç‰¹ç‚¹ï¼š
    - Milvuså‘é‡æ•°æ®åº“
    - HNSWç´¢å¼•ï¼ˆé«˜æ€§èƒ½ï¼‰
    - æ”¯æŒè¿‡æ»¤æ¡ä»¶

    ğŸ’¡ é€‚ç”¨åœºæ™¯ï¼š
    - è¯­ä¹‰ç›¸ä¼¼æ£€ç´¢
    - æ¨¡ç³ŠåŒ¹é…
    - è·¨è¯­è¨€æ£€ç´¢
    """

    def __init__(
            self,
            collection_name: str,
            embedder: Embedder,
            host: str = 'localhost',
            port: str = '19530',
            dim: int = 1024
    ):
        """
        åˆå§‹åŒ–å‘é‡æ£€ç´¢å™¨

        å‚æ•°ï¼š
            collection_name: é›†åˆåç§°ï¼ˆç›¸å½“äºè¡¨åï¼‰
            embedder: å‘é‡åŒ–æœåŠ¡å®ä¾‹
            host: MilvusæœåŠ¡å™¨åœ°å€
            port: Milvusç«¯å£
            dim: å‘é‡ç»´åº¦
        """
        self.collection_name = collection_name
        self.embedder = embedder
        self.host = host
        self.port = port
        self.dim = dim

        # è¿æ¥Milvus
        self._connect()

        # åˆå§‹åŒ–é›†åˆ
        self.collection = None

        logger.info(
            f"å‘é‡æ£€ç´¢å™¨åˆå§‹åŒ– | "
            f"é›†åˆ: {collection_name} | "
            f"ç»´åº¦: {dim}"
        )

    def _connect(self):
        """è¿æ¥MilvusæœåŠ¡å™¨"""
        try:
            connections.connect(
                alias="default",
                host=self.host,
                port=self.port
            )
            logger.info(f"å·²è¿æ¥åˆ°Milvus | {self.host}:{self.port}")
        except Exception as e:
            logger.error(f"è¿æ¥Milvuså¤±è´¥: {e}")
            raise

    def create_collection(
            self,
            drop_if_exists: bool = False
    ):
        """
        åˆ›å»ºé›†åˆ

        å‚æ•°ï¼š
            drop_if_exists: å¦‚æœé›†åˆå­˜åœ¨æ˜¯å¦åˆ é™¤
        """
        # æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨
        if utility.has_collection(self.collection_name):
            if drop_if_exists:
                logger.warning(f"åˆ é™¤å·²å­˜åœ¨çš„é›†åˆ: {self.collection_name}")
                utility.drop_collection(self.collection_name)
            else:
                logger.info(f"é›†åˆå·²å­˜åœ¨: {self.collection_name}")
                self.collection = Collection(self.collection_name)
                return

        # å®šä¹‰å­—æ®µ
        fields = [
            FieldSchema(
                name="id",
                dtype=DataType.INT64,
                is_primary=True,
                auto_id=True
            ),
            FieldSchema(
                name="doc_id",
                dtype=DataType.VARCHAR,
                max_length=200
            ),
            FieldSchema(
                name="text",
                dtype=DataType.VARCHAR,
                max_length=65535
            ),
            FieldSchema(
                name="embedding",
                dtype=DataType.FLOAT_VECTOR,
                dim=self.dim
            ),
            FieldSchema(
                name="metadata",
                dtype=DataType.JSON
            )
        ]

        # åˆ›å»ºSchema
        schema = CollectionSchema(
            fields=fields,
            description=f"Vector collection for {self.collection_name}"
        )

        # åˆ›å»ºé›†åˆ
        self.collection = Collection(
            name=self.collection_name,
            schema=schema
        )

        logger.info(f"é›†åˆåˆ›å»ºæˆåŠŸ: {self.collection_name}")

    def create_index(
            self,
            index_type: str = "HNSW",
            metric_type: str = "IP",  # IP (å†…ç§¯) æˆ– L2 (æ¬§æ°è·ç¦»)
            params: Optional[Dict] = None
    ):
        """
        åˆ›å»ºå‘é‡ç´¢å¼•

        å‚æ•°ï¼š
            index_type: ç´¢å¼•ç±»å‹
                - 'HNSW': é«˜æ€§èƒ½ï¼ˆæ¨èï¼‰
                - 'IVF_FLAT': ç²¾ç¡®æ£€ç´¢
                - 'IVF_SQ8': å†…å­˜ä¼˜åŒ–
            metric_type: è·ç¦»åº¦é‡
                - 'IP': å†…ç§¯ï¼ˆé€‚åˆå½’ä¸€åŒ–å‘é‡ï¼‰
                - 'L2': æ¬§æ°è·ç¦»
                - 'COSINE': ä½™å¼¦ç›¸ä¼¼åº¦
            params: ç´¢å¼•å‚æ•°
        """
        if not self.collection:
            raise RuntimeError("é›†åˆæœªåˆ›å»ºï¼Œè¯·å…ˆè°ƒç”¨create_collection()")

        # é»˜è®¤ç´¢å¼•å‚æ•°
        if params is None:
            if index_type == "HNSW":
                params = {
                    "M": 16,  # æ¯ä¸ªèŠ‚ç‚¹çš„æœ€å¤§è¿æ¥æ•°
                    "efConstruction": 256  # æ„å»ºæ—¶çš„å€™é€‰æ•°
                }
            elif index_type == "IVF_FLAT":
                params = {
                    "nlist": 1024  # èšç±»ä¸­å¿ƒæ•°
                }
            elif index_type == "IVF_SQ8":
                params = {
                    "nlist": 1024
                }

        # åˆ›å»ºç´¢å¼•
        index_params = {
            "index_type": index_type,
            "metric_type": metric_type,
            "params": params
        }

        logger.info(f"å¼€å§‹åˆ›å»ºç´¢å¼• | ç±»å‹: {index_type} | åº¦é‡: {metric_type}")

        self.collection.create_index(
            field_name="embedding",
            index_params=index_params
        )

        logger.info("ç´¢å¼•åˆ›å»ºå®Œæˆ")

    def insert(
            self,
            documents: List[Dict],
            batch_size: int = 100
    ) -> int:
        """
        æ’å…¥æ–‡æ¡£

        å‚æ•°ï¼š
            documents: æ–‡æ¡£åˆ—è¡¨
                [
                    {
                        'doc_id': 'doc1',
                        'text': 'æ–‡æ¡£å†…å®¹',
                        'embedding': np.ndarray,  # å¯é€‰ï¼Œå¦‚æ²¡æœ‰ä¼šè‡ªåŠ¨ç”Ÿæˆ
                        'metadata': {...}
                    },
                    ...
                ]
            batch_size: æ‰¹å¤„ç†å¤§å°

        è¿”å›ï¼š
            æ’å…¥çš„æ–‡æ¡£æ•°é‡
        """
        if not self.collection:
            raise RuntimeError("é›†åˆæœªåˆ›å»º")

        logger.info(f"å¼€å§‹æ’å…¥æ–‡æ¡£ | æ•°é‡: {len(documents)}")

        total_inserted = 0

        # åˆ†æ‰¹æ’å…¥
        for i in range(0, len(documents), batch_size):
            batch = documents[i:i + batch_size]

            # å‡†å¤‡æ•°æ®
            doc_ids = []
            texts = []
            embeddings = []
            metadatas = []

            for doc in batch:
                doc_ids.append(doc.get('doc_id', f"doc_{i}"))
                texts.append(doc.get('text', ''))

                # å¦‚æœæ²¡æœ‰embeddingï¼Œè‡ªåŠ¨ç”Ÿæˆ
                if 'embedding' in doc:
                    embeddings.append(doc['embedding'].tolist())
                else:
                    # ä½¿ç”¨embedderç”Ÿæˆå‘é‡
                    emb = self.embedder.embed_query(doc.get('text', ''))
                    embeddings.append(emb.tolist())

                metadatas.append(doc.get('metadata', {}))

            # æ’å…¥
            entities = [
                doc_ids,
                texts,
                embeddings,
                metadatas
            ]

            insert_result = self.collection.insert(entities)
            total_inserted += len(insert_result.primary_keys)

            logger.debug(f"æ‰¹æ¬¡ {i // batch_size + 1} æ’å…¥å®Œæˆ: {len(batch)} æ¡")

        # åˆ·æ–°
        self.collection.flush()

        logger.info(f"æ–‡æ¡£æ’å…¥å®Œæˆ | æ€»è®¡: {total_inserted} æ¡")

        return total_inserted

    def search(
            self,
            query: str,
            top_k: int = 10,
            filters: Optional[str] = None,
            search_params: Optional[Dict] = None
    ) -> List[Dict]:
        """
        æ£€ç´¢æ–‡æ¡£

        å‚æ•°ï¼š
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›å‰Kä¸ªç»“æœ
            filters: è¿‡æ»¤è¡¨è¾¾å¼ï¼ˆMilvusè¯­æ³•ï¼‰
                ä¾‹å¦‚: "metadata['type'] == 'regulation'"
            search_params: æ£€ç´¢å‚æ•°
                ä¾‹å¦‚: {"ef": 64} for HNSW

        è¿”å›ï¼š
            æ£€ç´¢ç»“æœåˆ—è¡¨
        """
        if not self.collection:
            raise RuntimeError("é›†åˆæœªåˆ›å»º")

        logger.debug(f"å‘é‡æ£€ç´¢ | æŸ¥è¯¢: {query[:50]}... | top_k: {top_k}")

        # åŠ è½½é›†åˆåˆ°å†…å­˜
        self.collection.load()

        # æŸ¥è¯¢å‘é‡åŒ–
        query_embedding = self.embedder.embed_query(query)

        # é»˜è®¤æ£€ç´¢å‚æ•°
        if search_params is None:
            search_params = {"ef": 64}  # HNSWå‚æ•°

        # æ‰§è¡Œæ£€ç´¢
        search_results = self.collection.search(
            data=[query_embedding.tolist()],
            anns_field="embedding",
            param=search_params,
            limit=top_k,
            expr=filters,
            output_fields=["doc_id", "text", "metadata"]
        )

        # è§£æç»“æœ
        results = []
        for rank, hit in enumerate(search_results[0], 1):
            result = {
                'doc_id': hit.entity.get('doc_id'),
                'text': hit.entity.get('text'),
                'metadata': hit.entity.get('metadata'),
                'score': float(hit.score),  # è·ç¦»/ç›¸ä¼¼åº¦åˆ†æ•°
                'rank': rank
            }
            results.append(result)

        logger.debug(f"å‘é‡æ£€ç´¢å®Œæˆ | è¿”å›: {len(results)} ä¸ªç»“æœ")

        return results

    def delete(self, expr: str) -> int:
        """
        åˆ é™¤æ–‡æ¡£

        å‚æ•°ï¼š
            expr: åˆ é™¤æ¡ä»¶è¡¨è¾¾å¼
                ä¾‹å¦‚: "doc_id in ['doc1', 'doc2']"

        è¿”å›ï¼š
            åˆ é™¤çš„æ–‡æ¡£æ•°é‡
        """
        if not self.collection:
            raise RuntimeError("é›†åˆæœªåˆ›å»º")

        delete_result = self.collection.delete(expr)

        logger.info(f"åˆ é™¤æ–‡æ¡£: {delete_result.delete_count} æ¡")

        return delete_result.delete_count

    def get_stats(self) -> Dict:
        """è·å–é›†åˆç»Ÿè®¡ä¿¡æ¯"""
        if not self.collection:
            return {}

        stats = self.collection.num_entities

        return {
            'collection_name': self.collection_name,
            'total_docs': stats,
            'dimension': self.dim
        }

    def drop_collection(self):
        """åˆ é™¤é›†åˆ"""
        if utility.has_collection(self.collection_name):
            utility.drop_collection(self.collection_name)
            logger.info(f"é›†åˆå·²åˆ é™¤: {self.collection_name}")
        else:
            logger.warning(f"é›†åˆä¸å­˜åœ¨: {self.collection_name}")


# =========================================
# ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹
# =========================================
"""
from services.retrieval.vector_retriever import VectorRetriever
from services.embedding.embedder import Embedder
from services.embedding.embedding_model import EmbeddingModel

# 1. åˆå§‹åŒ–
model = EmbeddingModel(model_name='BAAI/bge-large-zh-v1.5')
embedder = Embedder(embedding_model=model)

retriever = VectorRetriever(
    collection_name='documents',
    embedder=embedder,
    host='localhost',
    port='19530',
    dim=1024
)

# 2. åˆ›å»ºé›†åˆå’Œç´¢å¼•
retriever.create_collection(drop_if_exists=True)
retriever.create_index(index_type='HNSW', metric_type='IP')

# 3. æ’å…¥æ–‡æ¡£
documents = [
    {
        'doc_id': 'doc1',
        'text': 'å»ºç­‘ç»“æ„è·è½½è§„èŒƒ GB50009-2012',
        'metadata': {'type': 'regulation', 'year': 2012}
    },
    {
        'doc_id': 'doc2',
        'text': 'å»ºç­‘æŠ—éœ‡è®¾è®¡è§„èŒƒ GB50011-2010',
        'metadata': {'type': 'regulation', 'year': 2010}
    }
]

retriever.insert(documents)

# 4. æ£€ç´¢
query = "å»ºç­‘ç»“æ„è·è½½å¦‚ä½•è®¡ç®—ï¼Ÿ"
results = retriever.search(query, top_k=5)

for result in results:
    print(f"æ’å: {result['rank']}")
    print(f"ç›¸ä¼¼åº¦: {result['score']:.4f}")
    print(f"æ–‡æ¡£: {result['text']}")
    print("---")

# 5. å¸¦è¿‡æ»¤æ¡ä»¶çš„æ£€ç´¢
results = retriever.search(
    query="å»ºç­‘è§„èŒƒ",
    top_k=5,
    filters="metadata['year'] >= 2010"
)

# 6. æŸ¥çœ‹ç»Ÿè®¡
stats = retriever.get_stats()
print(f"é›†åˆç»Ÿè®¡: {stats}")
"""