"""
========================================
å›¾è°±å¢å¼ºæ£€ç´¢å™¨ - Graph-Enhanced RAG
========================================

ğŸ“š æ¨¡å—è¯´æ˜ï¼š
- æ•´åˆå‘é‡æ£€ç´¢ã€BM25 æ£€ç´¢å’Œå›¾è°±æ£€ç´¢
- å®ç°ä¸‰è·¯å¬å› + èåˆ + é‡æ’åº
- æä¾›å›¾è°±çŸ¥è¯†å¢å¼ºçš„ RAG æ£€ç´¢

ğŸ¯ æ ¸å¿ƒåŠŸèƒ½ï¼š
1. ä¸‰è·¯æ£€ç´¢ï¼ˆå‘é‡ + BM25 + å›¾è°±ï¼‰
2. æ™ºèƒ½èåˆï¼ˆRRF + å›¾è°±åŠ æƒï¼‰
3. ä¸Šä¸‹æ–‡å¢å¼ºï¼ˆå›¾è°±çŸ¥è¯†æ³¨å…¥ï¼‰
4. å®ä½“é“¾æ¥ï¼ˆæŸ¥è¯¢å®ä½“è¯†åˆ«ï¼‰

ğŸ”§ æ£€ç´¢æµç¨‹ï¼š
1. æŸ¥è¯¢åˆ†æ â†’ å®ä½“è¯†åˆ«
2. ä¸‰è·¯å¹¶è¡Œæ£€ç´¢
3. ç»“æœèåˆï¼ˆè€ƒè™‘å›¾è°±æƒé‡ï¼‰
4. Rerank é‡æ’åº
5. å›¾è°±ä¸Šä¸‹æ–‡å¢å¼º

========================================
"""

from typing import List, Dict, Any, Optional, Literal
import asyncio
from loguru import logger

from core.config import settings


class GraphEnhancedRetriever:
    """
    å›¾è°±å¢å¼ºæ£€ç´¢å™¨

    ğŸ”§ ç‰¹æ€§ï¼š
    - ä¸‰è·¯å¬å›ï¼šå‘é‡ + BM25 + çŸ¥è¯†å›¾è°±
    - æ™ºèƒ½èåˆï¼šRRF ç®—æ³• + å›¾è°±æƒé‡æå‡
    - ä¸Šä¸‹æ–‡å¢å¼ºï¼šå°†å›¾è°±çŸ¥è¯†æ³¨å…¥æ£€ç´¢ç»“æœ
    - å®ä½“æ„ŸçŸ¥ï¼šè¯†åˆ«æŸ¥è¯¢ä¸­çš„å®ä½“å¹¶å…³è”å›¾è°±

    ğŸ’¡ ä¼˜åŠ¿ï¼š
    - ç»“åˆè¯­ä¹‰ç†è§£å’Œç»“æ„åŒ–çŸ¥è¯†
    - æé«˜ä¸“ä¸šæœ¯è¯­çš„æ£€ç´¢å‡†ç¡®ç‡
    - æ”¯æŒå®ä½“å…³ç³»æ¨ç†
    - å¢å¼ºç­”æ¡ˆçš„å¯è§£é‡Šæ€§
    """

    def __init__(
        self,
        bm25_retriever=None,
        vector_retriever=None,
        graph_retriever=None,
        reranker=None,
        fusion_method: Literal['rrf', 'weighted'] = 'rrf',
        graph_weight: float = 0.3,
        enable_context_enhancement: bool = True
    ):
        """
        åˆå§‹åŒ–å›¾è°±å¢å¼ºæ£€ç´¢å™¨

        å‚æ•°ï¼š
            bm25_retriever: BM25 æ£€ç´¢å™¨
            vector_retriever: å‘é‡æ£€ç´¢å™¨
            graph_retriever: å›¾è°±æ£€ç´¢å™¨
            reranker: é‡æ’åºå™¨
            fusion_method: èåˆæ–¹æ³• ('rrf' æˆ– 'weighted')
            graph_weight: å›¾è°±æ£€ç´¢æƒé‡ (0-1)
            enable_context_enhancement: æ˜¯å¦å¯ç”¨ä¸Šä¸‹æ–‡å¢å¼º
        """
        self.bm25_retriever = bm25_retriever
        self.vector_retriever = vector_retriever
        self.graph_retriever = graph_retriever
        self.reranker = reranker
        self.fusion_method = fusion_method
        self.graph_weight = graph_weight
        self.enable_context_enhancement = enable_context_enhancement

        # æƒé‡é…ç½®
        self.weights = {
            'bm25': settings.BM25_WEIGHT if hasattr(settings, 'BM25_WEIGHT') else 0.3,
            'vector': settings.VECTOR_WEIGHT if hasattr(settings, 'VECTOR_WEIGHT') else 0.4,
            'graph': graph_weight
        }

        # å»¶è¿Ÿåˆå§‹åŒ–æ ‡å¿—
        self._initialized = False

        logger.info(
            f"å›¾è°±å¢å¼ºæ£€ç´¢å™¨åˆå§‹åŒ– | "
            f"BM25: {bm25_retriever is not None} | "
            f"Vector: {vector_retriever is not None} | "
            f"Graph: {graph_retriever is not None} | "
            f"èåˆæ–¹æ³•: {fusion_method} | "
            f"å›¾è°±æƒé‡: {graph_weight}"
        )

    def _lazy_init(self):
        """æ‡’åŠ è½½åˆå§‹åŒ–ç»„ä»¶"""
        if self._initialized:
            return

        # åˆå§‹åŒ–å›¾è°±æ£€ç´¢å™¨ï¼ˆå¦‚æœæœªæä¾›ï¼‰
        if self.graph_retriever is None:
            try:
                from services.retrieval.graph.graph_retriever import GraphRetriever
                self.graph_retriever = GraphRetriever(
                    enable_entity_extraction=True,
                    max_entities=5,
                    relation_depth=2
                )
                logger.info("å›¾è°±æ£€ç´¢å™¨å·²è‡ªåŠ¨åˆå§‹åŒ–")
            except Exception as e:
                logger.warning(f"å›¾è°±æ£€ç´¢å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
                self.graph_retriever = None

        self._initialized = True

    def search(
        self,
        query: str,
        top_k: int = 10,
        bm25_top_k: Optional[int] = None,
        vector_top_k: Optional[int] = None,
        graph_top_k: Optional[int] = None,
        use_rerank: bool = True,
        rerank_top_k: Optional[int] = None,
        filters: Optional[str] = None,
        document_id: Optional[str] = None,
        fusion_weights: Optional[Dict[str, float]] = None,
        enhance_with_graph: bool = True
    ) -> List[Dict[str, Any]]:
        """
        å›¾è°±å¢å¼ºæ··åˆæ£€ç´¢

        å‚æ•°ï¼š
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: æœ€ç»ˆè¿”å›æ•°é‡
            bm25_top_k: BM25 æ£€ç´¢æ•°é‡
            vector_top_k: å‘é‡æ£€ç´¢æ•°é‡
            graph_top_k: å›¾è°±æ£€ç´¢æ•°é‡
            use_rerank: æ˜¯å¦ä½¿ç”¨é‡æ’åº
            rerank_top_k: é‡æ’åºå€™é€‰æ•°é‡
            filters: å‘é‡æ£€ç´¢è¿‡æ»¤æ¡ä»¶
            document_id: é™å®šæ–‡æ¡£ ID
            fusion_weights: è‡ªå®šä¹‰èåˆæƒé‡
            enhance_with_graph: æ˜¯å¦ç”¨å›¾è°±çŸ¥è¯†å¢å¼ºç»“æœ

        è¿”å›ï¼š
            æ£€ç´¢ç»“æœåˆ—è¡¨
        """
        self._lazy_init()

        logger.info(f"å›¾è°±å¢å¼ºæ£€ç´¢ | æŸ¥è¯¢: {query[:50]}... | top_k: {top_k}")

        # è®¾ç½®é»˜è®¤æ£€ç´¢æ•°é‡
        if bm25_top_k is None:
            bm25_top_k = top_k * 3
        if vector_top_k is None:
            vector_top_k = top_k * 3
        if graph_top_k is None:
            graph_top_k = top_k * 2

        # Step 1: ä¸‰è·¯å¹¶è¡Œæ£€ç´¢
        bm25_results = []
        vector_results = []
        graph_results = []

        # BM25 æ£€ç´¢
        if self.bm25_retriever:
            try:
                bm25_results = self.bm25_retriever.search(
                    query=query,
                    top_k=bm25_top_k,
                    return_scores=True
                )
                logger.debug(f"BM25 æ£€ç´¢å®Œæˆ | ç»“æœæ•°: {len(bm25_results)}")
            except Exception as e:
                logger.warning(f"BM25 æ£€ç´¢å¤±è´¥: {e}")

        # å‘é‡æ£€ç´¢
        if self.vector_retriever:
            try:
                vector_results = self.vector_retriever.search(
                    query=query,
                    top_k=vector_top_k,
                    filters=filters
                )
                logger.debug(f"å‘é‡æ£€ç´¢å®Œæˆ | ç»“æœæ•°: {len(vector_results)}")
            except Exception as e:
                logger.warning(f"å‘é‡æ£€ç´¢å¤±è´¥: {e}")

        # å›¾è°±æ£€ç´¢
        if self.graph_retriever and self.graph_retriever.is_available():
            try:
                graph_results = self.graph_retriever.search(
                    query=query,
                    top_k=graph_top_k,
                    document_id=document_id,
                    return_context=True
                )
                logger.debug(f"å›¾è°±æ£€ç´¢å®Œæˆ | ç»“æœæ•°: {len(graph_results)}")
            except Exception as e:
                logger.warning(f"å›¾è°±æ£€ç´¢å¤±è´¥: {e}")

        # Step 2: ç»“æœèåˆ
        fused_results = self._fuse_three_way_results(
            bm25_results=bm25_results,
            vector_results=vector_results,
            graph_results=graph_results,
            fusion_weights=fusion_weights
        )

        # é™åˆ¶å€™é€‰æ•°é‡
        if rerank_top_k is None:
            rerank_top_k = min(top_k * 3, len(fused_results))
        fused_results = fused_results[:rerank_top_k]

        # Step 3: é‡æ’åº
        if use_rerank and self.reranker and fused_results:
            logger.debug(f"é‡æ’åº | å€™é€‰æ•°: {len(fused_results)}")
            try:
                fused_results = self.reranker.rerank(
                    query=query,
                    documents=fused_results,
                    text_key='text',
                    top_k=None,
                    return_scores=True
                )
            except Exception as e:
                logger.warning(f"é‡æ’åºå¤±è´¥: {e}")

        # Step 4: å›¾è°±ä¸Šä¸‹æ–‡å¢å¼º
        if enhance_with_graph and self.enable_context_enhancement and graph_results:
            fused_results = self._enhance_with_graph_context(
                results=fused_results,
                graph_results=graph_results,
                query=query
            )

        # Step 5: è¿”å› Top-K
        final_results = fused_results[:top_k]

        logger.info(
            f"å›¾è°±å¢å¼ºæ£€ç´¢å®Œæˆ | "
            f"BM25: {len(bm25_results)} | "
            f"Vector: {len(vector_results)} | "
            f"Graph: {len(graph_results)} | "
            f"æœ€ç»ˆ: {len(final_results)}"
        )

        return final_results

    async def search_async(
        self,
        query: str,
        top_k: int = 10,
        **kwargs
    ) -> List[Dict[str, Any]]:
        """
        å¼‚æ­¥å›¾è°±å¢å¼ºæ£€ç´¢

        å¹¶è¡Œæ‰§è¡Œä¸‰è·¯æ£€ç´¢ä»¥æé«˜æ•ˆç‡
        """
        self._lazy_init()

        logger.info(f"å¼‚æ­¥å›¾è°±å¢å¼ºæ£€ç´¢ | æŸ¥è¯¢: {query[:50]}...")

        bm25_top_k = kwargs.get('bm25_top_k', top_k * 3)
        vector_top_k = kwargs.get('vector_top_k', top_k * 3)
        graph_top_k = kwargs.get('graph_top_k', top_k * 2)
        filters = kwargs.get('filters')
        document_id = kwargs.get('document_id')

        # å¹¶è¡Œæ‰§è¡Œä¸‰è·¯æ£€ç´¢
        async def _bm25_search():
            if not self.bm25_retriever:
                return []
            try:
                return self.bm25_retriever.search(query=query, top_k=bm25_top_k, return_scores=True)
            except Exception as e:
                logger.warning(f"BM25 æ£€ç´¢å¤±è´¥: {e}")
                return []

        async def _vector_search():
            if not self.vector_retriever:
                return []
            try:
                return self.vector_retriever.search(query=query, top_k=vector_top_k, filters=filters)
            except Exception as e:
                logger.warning(f"å‘é‡æ£€ç´¢å¤±è´¥: {e}")
                return []

        async def _graph_search():
            if not self.graph_retriever or not self.graph_retriever.is_available():
                return []
            try:
                return self.graph_retriever.search(query=query, top_k=graph_top_k, document_id=document_id)
            except Exception as e:
                logger.warning(f"å›¾è°±æ£€ç´¢å¤±è´¥: {e}")
                return []

        # å¹¶è¡Œæ‰§è¡Œ
        bm25_results, vector_results, graph_results = await asyncio.gather(
            _bm25_search(),
            _vector_search(),
            _graph_search()
        )

        # èåˆç»“æœ
        fused_results = self._fuse_three_way_results(
            bm25_results=bm25_results,
            vector_results=vector_results,
            graph_results=graph_results,
            fusion_weights=kwargs.get('fusion_weights')
        )

        # é‡æ’åº
        use_rerank = kwargs.get('use_rerank', True)
        rerank_top_k = kwargs.get('rerank_top_k', min(top_k * 3, len(fused_results)))
        fused_results = fused_results[:rerank_top_k]

        if use_rerank and self.reranker and fused_results:
            try:
                fused_results = self.reranker.rerank(
                    query=query,
                    documents=fused_results,
                    text_key='text',
                    top_k=None,
                    return_scores=True
                )
            except Exception as e:
                logger.warning(f"é‡æ’åºå¤±è´¥: {e}")

        # å›¾è°±ä¸Šä¸‹æ–‡å¢å¼º
        enhance_with_graph = kwargs.get('enhance_with_graph', True)
        if enhance_with_graph and self.enable_context_enhancement and graph_results:
            fused_results = self._enhance_with_graph_context(
                results=fused_results,
                graph_results=graph_results,
                query=query
            )

        return fused_results[:top_k]

    def _fuse_three_way_results(
        self,
        bm25_results: List[Dict],
        vector_results: List[Dict],
        graph_results: List[Dict],
        fusion_weights: Optional[Dict[str, float]] = None
    ) -> List[Dict[str, Any]]:
        """
        ä¸‰è·¯ç»“æœèåˆ

        ä½¿ç”¨ RRF ç®—æ³•èåˆä¸‰è·¯æ£€ç´¢ç»“æœï¼Œå¹¶å¯¹å›¾è°±ç»“æœè¿›è¡ŒåŠ æƒæå‡
        """
        if fusion_weights is None:
            fusion_weights = self.weights

        if self.fusion_method == 'rrf':
            return self._rrf_three_way_fusion(
                bm25_results,
                vector_results,
                graph_results,
                fusion_weights
            )
        else:
            return self._weighted_three_way_fusion(
                bm25_results,
                vector_results,
                graph_results,
                fusion_weights
            )

    def _rrf_three_way_fusion(
        self,
        bm25_results: List[Dict],
        vector_results: List[Dict],
        graph_results: List[Dict],
        fusion_weights: Dict[str, float],
        k: int = 60
    ) -> List[Dict[str, Any]]:
        """
        ä¸‰è·¯ RRF èåˆ

        å…¬å¼ï¼šRRF_score = Î£ (weight_i / (k + rank_i))
        """
        doc_scores = {}
        doc_data = {}

        # BM25 ç»“æœ
        bm25_weight = fusion_weights.get('bm25', 0.3)
        for rank, doc in enumerate(bm25_results, 1):
            doc_id = self._get_doc_id(doc)
            rrf_score = bm25_weight / (k + rank)

            if doc_id not in doc_scores:
                doc_scores[doc_id] = 0
                doc_data[doc_id] = doc.copy()

            doc_scores[doc_id] += rrf_score
            doc_data[doc_id]['bm25_rank'] = rank
            doc_data[doc_id]['bm25_score'] = doc.get('score', 0)

        # å‘é‡ç»“æœ
        vector_weight = fusion_weights.get('vector', 0.4)
        for rank, doc in enumerate(vector_results, 1):
            doc_id = self._get_doc_id(doc)
            rrf_score = vector_weight / (k + rank)

            if doc_id not in doc_scores:
                doc_scores[doc_id] = 0
                doc_data[doc_id] = doc.copy()

            doc_scores[doc_id] += rrf_score
            doc_data[doc_id]['vector_rank'] = rank
            doc_data[doc_id]['vector_score'] = doc.get('score', 0)

        # å›¾è°±ç»“æœï¼ˆç‰¹æ®Šå¤„ç†ï¼‰
        graph_weight = fusion_weights.get('graph', 0.3)
        for rank, doc in enumerate(graph_results, 1):
            doc_id = self._get_doc_id(doc)

            # å›¾è°±ç»“æœä½¿ç”¨æ›´é«˜çš„åŸºç¡€åˆ†æ•°
            rrf_score = graph_weight / (k + rank)

            # å¦‚æœå›¾è°±ç»“æœåŒ…å«ä¸Šä¸‹æ–‡ï¼Œé¢å¤–åŠ åˆ†
            if doc.get('context') or doc.get('relations'):
                rrf_score *= 1.2  # å›¾è°±ä¸Šä¸‹æ–‡åŠ æˆ

            if doc_id not in doc_scores:
                doc_scores[doc_id] = 0
                doc_data[doc_id] = doc.copy()

            doc_scores[doc_id] += rrf_score
            doc_data[doc_id]['graph_rank'] = rank
            doc_data[doc_id]['graph_score'] = doc.get('score', 0)
            doc_data[doc_id]['has_graph_context'] = bool(doc.get('context'))

            # ä¿å­˜å›¾è°±ä¸Šä¸‹æ–‡
            if doc.get('context'):
                doc_data[doc_id]['graph_context'] = doc.get('context')
            if doc.get('relations'):
                doc_data[doc_id]['graph_relations'] = doc.get('relations')
            if doc.get('entity'):
                doc_data[doc_id]['graph_entity'] = doc.get('entity')

        # æŒ‰èåˆåˆ†æ•°æ’åº
        sorted_docs = sorted(
            doc_data.values(),
            key=lambda x: doc_scores.get(self._get_doc_id(x), 0),
            reverse=True
        )

        # æ·»åŠ èåˆä¿¡æ¯
        for rank, doc in enumerate(sorted_docs, 1):
            doc_id = self._get_doc_id(doc)
            doc['fusion_score'] = doc_scores.get(doc_id, 0)
            doc['fusion_rank'] = rank
            doc['retrieval_sources'] = self._get_retrieval_sources(doc)

        return sorted_docs

    def _weighted_three_way_fusion(
        self,
        bm25_results: List[Dict],
        vector_results: List[Dict],
        graph_results: List[Dict],
        fusion_weights: Dict[str, float]
    ) -> List[Dict[str, Any]]:
        """
        ä¸‰è·¯åŠ æƒèåˆ
        """
        all_docs = {}

        # å½’ä¸€åŒ–å‡½æ•°
        def normalize_scores(docs, score_key='score'):
            if not docs:
                return []
            scores = [d.get(score_key, 0) for d in docs]
            min_s, max_s = min(scores), max(scores)
            if max_s == min_s:
                return [(d, 1.0) for d in docs]
            return [(d, (d.get(score_key, 0) - min_s) / (max_s - min_s)) for d in docs]

        # BM25 ç»“æœ
        bm25_weight = fusion_weights.get('bm25', 0.3)
        for doc, norm_score in normalize_scores(bm25_results):
            doc_id = self._get_doc_id(doc)
            if doc_id not in all_docs:
                all_docs[doc_id] = doc.copy()
                all_docs[doc_id]['weighted_score'] = 0
            all_docs[doc_id]['weighted_score'] += norm_score * bm25_weight
            all_docs[doc_id]['bm25_score'] = doc.get('score', 0)

        # å‘é‡ç»“æœ
        vector_weight = fusion_weights.get('vector', 0.4)
        for doc, norm_score in normalize_scores(vector_results):
            doc_id = self._get_doc_id(doc)
            if doc_id not in all_docs:
                all_docs[doc_id] = doc.copy()
                all_docs[doc_id]['weighted_score'] = 0
            all_docs[doc_id]['weighted_score'] += norm_score * vector_weight
            all_docs[doc_id]['vector_score'] = doc.get('score', 0)

        # å›¾è°±ç»“æœ
        graph_weight = fusion_weights.get('graph', 0.3)
        for doc, norm_score in normalize_scores(graph_results):
            doc_id = self._get_doc_id(doc)

            # å›¾è°±ä¸Šä¸‹æ–‡åŠ æˆ
            context_bonus = 0.1 if doc.get('context') else 0

            if doc_id not in all_docs:
                all_docs[doc_id] = doc.copy()
                all_docs[doc_id]['weighted_score'] = 0
            all_docs[doc_id]['weighted_score'] += (norm_score + context_bonus) * graph_weight
            all_docs[doc_id]['graph_score'] = doc.get('score', 0)
            all_docs[doc_id]['has_graph_context'] = bool(doc.get('context'))

            if doc.get('context'):
                all_docs[doc_id]['graph_context'] = doc.get('context')

        # æ’åº
        docs_list = list(all_docs.values())
        docs_list.sort(key=lambda x: x.get('weighted_score', 0), reverse=True)

        for rank, doc in enumerate(docs_list, 1):
            doc['fusion_rank'] = rank
            doc['fusion_score'] = doc.get('weighted_score', 0)

        return docs_list

    def _enhance_with_graph_context(
        self,
        results: List[Dict],
        graph_results: List[Dict],
        query: str
    ) -> List[Dict[str, Any]]:
        """
        ä½¿ç”¨å›¾è°±çŸ¥è¯†å¢å¼ºæ£€ç´¢ç»“æœ

        å°†å›¾è°±ä¸Šä¸‹æ–‡æ³¨å…¥åˆ°æ£€ç´¢ç»“æœä¸­ï¼Œæä¾›é¢å¤–çš„ç»“æ„åŒ–ä¿¡æ¯
        """
        # æ„å»ºå›¾è°±çŸ¥è¯†ç´¢å¼•
        graph_knowledge = {}
        for gr in graph_results:
            entity = gr.get('entity', {})
            entity_id = entity.get('id', '')
            if entity_id:
                graph_knowledge[entity_id] = {
                    'context': gr.get('context', ''),
                    'relations': gr.get('relations', []),
                    'related_entities': gr.get('related_entities', [])
                }

        # å¢å¼ºæ£€ç´¢ç»“æœ
        for result in results:
            # å¦‚æœç»“æœå·²ç»æœ‰å›¾è°±ä¸Šä¸‹æ–‡ï¼Œè·³è¿‡
            if result.get('has_graph_context'):
                continue

            # å°è¯•å…³è”å›¾è°±çŸ¥è¯†
            doc_text = result.get('text', '')

            # æŸ¥æ‰¾åŒ¹é…çš„å›¾è°±å®ä½“
            matched_contexts = []
            for entity_id, knowledge in graph_knowledge.items():
                # ç®€å•çš„æ–‡æœ¬åŒ¹é…
                if entity_id in doc_text or any(
                    rel.get('target_id', '') in doc_text
                    for rel in knowledge.get('relations', [])
                ):
                    if knowledge.get('context'):
                        matched_contexts.append(knowledge['context'])

            # æ·»åŠ å›¾è°±å¢å¼ºä¸Šä¸‹æ–‡
            if matched_contexts:
                result['graph_enhanced'] = True
                result['graph_context'] = ' '.join(matched_contexts[:2])  # æœ€å¤š2ä¸ª

        # æ„å»ºå…¨å±€å›¾è°±æ‘˜è¦ï¼ˆæ·»åŠ åˆ°ç¬¬ä¸€ä¸ªç»“æœï¼‰
        if results and graph_results:
            global_context = self._build_global_graph_summary(graph_results, query)
            if global_context:
                results[0]['global_graph_context'] = global_context

        return results

    def _build_global_graph_summary(
        self,
        graph_results: List[Dict],
        query: str
    ) -> str:
        """
        æ„å»ºå…¨å±€å›¾è°±æ‘˜è¦

        æ±‡æ€»æ‰€æœ‰å›¾è°±æ£€ç´¢ç»“æœï¼Œç”Ÿæˆç®€æ´çš„çŸ¥è¯†æ‘˜è¦
        """
        summary_parts = []

        # æ”¶é›†æ‰€æœ‰å®ä½“
        entities_by_type = {}
        for gr in graph_results[:5]:  # æœ€å¤š5ä¸ª
            entity = gr.get('entity', {})
            entity_type = entity.get('type', 'unknown')
            if entity_type not in entities_by_type:
                entities_by_type[entity_type] = []
            entities_by_type[entity_type].append(entity)

        # ç”Ÿæˆæ‘˜è¦
        if 'component' in entities_by_type:
            components = entities_by_type['component']
            codes = [c.get('properties', {}).get('code', '') for c in components if c.get('properties', {}).get('code')]
            if codes:
                summary_parts.append(f"ç›¸å…³æ„ä»¶: {', '.join(codes[:5])}")

        if 'material' in entities_by_type:
            materials = entities_by_type['material']
            grades = [m.get('properties', {}).get('grade', '') for m in materials if m.get('properties', {}).get('grade')]
            if grades:
                summary_parts.append(f"ç›¸å…³ææ–™: {', '.join(set(grades[:5]))}")

        if 'specification' in entities_by_type:
            specs = entities_by_type['specification']
            codes = [s.get('properties', {}).get('code', '') for s in specs if s.get('properties', {}).get('code')]
            if codes:
                summary_parts.append(f"ç›¸å…³è§„èŒƒ: {', '.join(codes[:3])}")

        if summary_parts:
            return "ã€çŸ¥è¯†å›¾è°±æ‘˜è¦ã€‘" + "; ".join(summary_parts)

        return ""

    def _get_doc_id(self, doc: Dict) -> str:
        """è·å–æ–‡æ¡£å”¯ä¸€æ ‡è¯†"""
        return doc.get('doc_id', doc.get('chunk_id', doc.get('id', str(id(doc)))))

    def _get_retrieval_sources(self, doc: Dict) -> List[str]:
        """è·å–æ£€ç´¢æ¥æº"""
        sources = []
        if 'bm25_rank' in doc:
            sources.append('bm25')
        if 'vector_rank' in doc:
            sources.append('vector')
        if 'graph_rank' in doc:
            sources.append('graph')
        return sources

    def get_graph_context_for_prompt(
        self,
        results: List[Dict]
    ) -> str:
        """
        è·å–ç”¨äº Prompt çš„å›¾è°±ä¸Šä¸‹æ–‡

        ä»æ£€ç´¢ç»“æœä¸­æå–å›¾è°±çŸ¥è¯†ï¼Œæ ¼å¼åŒ–ä¸º Prompt å¯ç”¨çš„æ–‡æœ¬
        """
        context_parts = []

        # å…¨å±€å›¾è°±ä¸Šä¸‹æ–‡
        for result in results:
            if result.get('global_graph_context'):
                context_parts.append(result['global_graph_context'])
                break

        # å•ä¸ªç»“æœçš„å›¾è°±ä¸Šä¸‹æ–‡
        for result in results[:5]:
            if result.get('graph_context'):
                context_parts.append(result['graph_context'])

        if context_parts:
            return "\n".join(context_parts)

        return ""


# =========================================
# ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹
# =========================================
"""
from services.retrieval.graph_enhanced_retriever import GraphEnhancedRetriever
from services.retrieval.bm25.bm25_engine import BM25Retriever
from services.retrieval.vector.vector_engine import VectorRetriever
from services.retrieval.graph.graph_retriever import GraphRetriever
from services.rerank.reranker import Reranker

# 1. åˆå§‹åŒ–å„ç»„ä»¶
bm25 = BM25Retriever()
vector = VectorRetriever(...)
graph = GraphRetriever()
reranker = Reranker()

# 2. åˆ›å»ºå›¾è°±å¢å¼ºæ£€ç´¢å™¨
retriever = GraphEnhancedRetriever(
    bm25_retriever=bm25,
    vector_retriever=vector,
    graph_retriever=graph,
    reranker=reranker,
    fusion_method='rrf',
    graph_weight=0.3
)

# 3. æ£€ç´¢
results = retriever.search(
    query="KL-1 æ¢çš„æ··å‡åœŸå¼ºåº¦ç­‰çº§æ˜¯å¤šå°‘ï¼Ÿ",
    top_k=5,
    use_rerank=True,
    enhance_with_graph=True
)

# 4. æŸ¥çœ‹ç»“æœ
for result in results:
    print(f"æ’å: {result['fusion_rank']}")
    print(f"æ¥æº: {result.get('retrieval_sources', [])}")
    print(f"æ–‡æœ¬: {result['text'][:100]}...")
    if result.get('graph_context'):
        print(f"å›¾è°±ä¸Šä¸‹æ–‡: {result['graph_context']}")
    print("---")

# 5. è·å–ç”¨äº Prompt çš„å›¾è°±ä¸Šä¸‹æ–‡
graph_context = retriever.get_graph_context_for_prompt(results)
print(f"å›¾è°±ä¸Šä¸‹æ–‡: {graph_context}")

# 6. å¼‚æ­¥æ£€ç´¢
import asyncio

async def main():
    results = await retriever.search_async(
        query="æ¡†æ¶æ¢ä½¿ç”¨ä»€ä¹ˆé’¢ç­‹ï¼Ÿ",
        top_k=5
    )
    return results

results = asyncio.run(main())
"""
