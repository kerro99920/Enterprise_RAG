"""
========================================
æ–‡æœ¬åˆ†å—å™¨
========================================

ğŸ“š æ¨¡å—è¯´æ˜ï¼š
- å°†é•¿æ–‡æ¡£åˆ‡åˆ†ä¸ºé€‚åˆæ£€ç´¢çš„å°å—
- ä¿æŒè¯­ä¹‰å®Œæ•´æ€§
- æ”¯æŒå¤šç§åˆ†å—ç­–ç•¥

ğŸ¯ æ ¸å¿ƒåŠŸèƒ½ï¼š
1. æ™ºèƒ½è¯­ä¹‰åˆ†å—
2. å›ºå®šé•¿åº¦åˆ†å—
3. é€’å½’åˆ†å—
4. æ»‘åŠ¨çª—å£

========================================
"""

import re
from typing import List, Dict, Optional, Callable
from dataclasses import dataclass

import jieba
from loguru import logger


@dataclass
class Chunk:
    """
    æ–‡æœ¬å—æ•°æ®ç±»

    å±æ€§ï¼š
        text: å—æ–‡æœ¬
        start_idx: åœ¨åŸæ–‡ä¸­çš„èµ·å§‹ä½ç½®
        end_idx: åœ¨åŸæ–‡ä¸­çš„ç»“æŸä½ç½®
        metadata: å—çš„å…ƒæ•°æ®
    """
    text: str
    start_idx: int
    end_idx: int
    metadata: Dict = None

    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}

    @property
    def length(self) -> int:
        """å—çš„é•¿åº¦ï¼ˆå­—ç¬¦æ•°ï¼‰"""
        return len(self.text)

    @property
    def token_count(self) -> int:
        """å—çš„tokenæ•°ï¼ˆä¸­æ–‡æŒ‰å­—æ•°ï¼Œè‹±æ–‡æŒ‰å•è¯æ•°ï¼‰"""
        # ç®€å•ä¼°ç®—ï¼šä¸­æ–‡1å­—=1tokenï¼Œè‹±æ–‡1è¯â‰ˆ1.3token
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', self.text))
        english_words = len(re.findall(r'[a-zA-Z]+', self.text))
        return chinese_chars + int(english_words * 1.3)


class DocumentSplitter:
    """
    æ–‡æ¡£åˆ†å—å™¨

    ğŸ”§ åˆ†å—ç­–ç•¥ï¼š
    1. semantic_split: è¯­ä¹‰åˆ†å—ï¼ˆæŒ‰æ®µè½ã€ç« èŠ‚ï¼‰
    2. fixed_split: å›ºå®šé•¿åº¦åˆ†å—
    3. recursive_split: é€’å½’åˆ†å—ï¼ˆä¼˜å…ˆä¿æŒè¯­ä¹‰ï¼‰
    4. sliding_window: æ»‘åŠ¨çª—å£åˆ†å—

    ğŸ’¡ è®¾è®¡åŸåˆ™ï¼š
    - å°½é‡ä¿æŒè¯­ä¹‰å®Œæ•´
    - é¿å…æˆªæ–­å¥å­
    - æ”¯æŒå—ä¹‹é—´çš„é‡å 
    """

    # é»˜è®¤åˆ†éš”ç¬¦ä¼˜å…ˆçº§ï¼ˆä»é«˜åˆ°ä½ï¼‰
    DEFAULT_SEPARATORS = [
        '\n\n\n',  # å¤§æ®µè½åˆ†éš”
        '\n\n',  # æ®µè½åˆ†éš”
        '\n',  # æ¢è¡Œ
        'ã€‚',  # ä¸­æ–‡å¥å·
        'ï¼',  # æ„Ÿå¹å·
        'ï¼Ÿ',  # é—®å·
        'ï¼›',  # åˆ†å·
        'ï¼Œ',  # é€—å·
        ' ',  # ç©ºæ ¼
        '',  # å­—ç¬¦çº§åˆ†å‰²ï¼ˆæœ€åæ‰‹æ®µï¼‰
    ]

    def __init__(
            self,
            chunk_size: int = 500,
            chunk_overlap: int = 50,
            separators: Optional[List[str]] = None
    ):
        """
        åˆå§‹åŒ–æ–‡æœ¬åˆ†å—å™¨

        å‚æ•°ï¼š
            chunk_size: ç›®æ ‡å—å¤§å°ï¼ˆå­—ç¬¦æ•°ï¼‰
            chunk_overlap: å—ä¹‹é—´çš„é‡å å¤§å°
            separators: è‡ªå®šä¹‰åˆ†éš”ç¬¦åˆ—è¡¨
        """
        self.chunk_size = chunk_size
        self.chunk_overlap = chunk_overlap
        self.separators = separators or self.DEFAULT_SEPARATORS

        logger.info(
            f"åˆå§‹åŒ–åˆ†å—å™¨ | chunk_size={chunk_size}, "
            f"overlap={chunk_overlap}"
        )

    def split(
            self,
            text: str,
            method: str = 'recursive',
            metadata: Optional[Dict] = None
    ) -> List[Chunk]:
        """
        åˆ†å—ä¸»å…¥å£

        å‚æ•°ï¼š
            text: å¾…åˆ†å—çš„æ–‡æœ¬
            method: åˆ†å—æ–¹æ³• ('semantic', 'fixed', 'recursive', 'sliding')
            metadata: æ–‡æ¡£å…ƒæ•°æ®ï¼ˆä¼šä¼ é€’ç»™æ¯ä¸ªå—ï¼‰

        è¿”å›ï¼š
            åˆ†å—åˆ—è¡¨
        """
        if not text or not text.strip():
            return []

        logger.debug(f"å¼€å§‹åˆ†å— | æ–¹æ³•: {method} | åŸå§‹é•¿åº¦: {len(text)}")

        # é€‰æ‹©åˆ†å—æ–¹æ³•
        if method == 'semantic':
            chunks = self._semantic_split(text)
        elif method == 'fixed':
            chunks = self._fixed_split(text)
        elif method == 'recursive':
            chunks = self._recursive_split(text)
        elif method == 'sliding':
            chunks = self._sliding_window_split(text)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„åˆ†å—æ–¹æ³•: {method}")

        # æ·»åŠ å…ƒæ•°æ®
        if metadata:
            for chunk in chunks:
                chunk.metadata.update(metadata)

        # æ·»åŠ å—åºå·
        for idx, chunk in enumerate(chunks):
            chunk.metadata['chunk_index'] = idx
            chunk.metadata['total_chunks'] = len(chunks)

        logger.info(
            f"åˆ†å—å®Œæˆ | æ–¹æ³•: {method} | "
            f"åŸå§‹é•¿åº¦: {len(text)} | "
            f"å—æ•°: {len(chunks)} | "
            f"å¹³å‡å—å¤§å°: {sum(c.length for c in chunks) / len(chunks):.0f}"
        )

        return chunks

    def _semantic_split(self, text: str) -> List[Chunk]:
        """
        è¯­ä¹‰åˆ†å— - æŒ‰æ®µè½å’Œç« èŠ‚åˆ†å‰²

        ç‰¹ç‚¹ï¼š
        - ä¿æŒæ®µè½å®Œæ•´
        - è¯†åˆ«ç« èŠ‚æ ‡é¢˜
        - ä¸ä¸¥æ ¼é™åˆ¶å—å¤§å°
        """
        chunks = []

        # æŒ‰åŒæ¢è¡Œåˆ†æ®µ
        paragraphs = re.split(r'\n\n+', text)

        current_chunk = ""
        current_start = 0

        for para in paragraphs:
            para = para.strip()
            if not para:
                continue

            # å¦‚æœæ˜¯æ ‡é¢˜ï¼Œä¸”å½“å‰æœ‰å†…å®¹ï¼Œå…ˆä¿å­˜å½“å‰å—
            if self._is_heading(para) and current_chunk:
                chunk = Chunk(
                    text=current_chunk.strip(),
                    start_idx=current_start,
                    end_idx=current_start + len(current_chunk),
                    metadata={'type': 'paragraph'}
                )
                chunks.append(chunk)
                current_chunk = ""
                current_start = current_start + len(current_chunk)

            # æ·»åŠ æ®µè½
            if current_chunk:
                current_chunk += "\n\n" + para
            else:
                current_chunk = para

            # å¦‚æœå—å¤ªå¤§ï¼Œåˆ†å‰²
            if len(current_chunk) > self.chunk_size * 2:
                chunk = Chunk(
                    text=current_chunk.strip(),
                    start_idx=current_start,
                    end_idx=current_start + len(current_chunk),
                    metadata={'type': 'paragraph'}
                )
                chunks.append(chunk)
                current_chunk = ""
                current_start = current_start + len(current_chunk)

        # æœ€åä¸€ä¸ªå—
        if current_chunk:
            chunk = Chunk(
                text=current_chunk.strip(),
                start_idx=current_start,
                end_idx=current_start + len(current_chunk),
                metadata={'type': 'paragraph'}
            )
            chunks.append(chunk)

        return chunks

    def _fixed_split(self, text: str) -> List[Chunk]:
        """
        å›ºå®šé•¿åº¦åˆ†å— - ä¸¥æ ¼æŒ‰å­—ç¬¦æ•°åˆ†å‰²

        ç‰¹ç‚¹ï¼š
        - å—å¤§å°å‡åŒ€
        - å¯èƒ½æˆªæ–­å¥å­
        - æ”¯æŒé‡å 
        """
        chunks = []
        start = 0

        while start < len(text):
            end = start + self.chunk_size
            chunk_text = text[start:end]

            chunk = Chunk(
                text=chunk_text,
                start_idx=start,
                end_idx=min(end, len(text)),
                metadata={'type': 'fixed'}
            )
            chunks.append(chunk)

            # è€ƒè™‘é‡å 
            start += (self.chunk_size - self.chunk_overlap)

        return chunks

    def _recursive_split(self, text: str) -> List[Chunk]:
        """
        é€’å½’åˆ†å— - ä¼˜å…ˆä½¿ç”¨é«˜çº§åˆ†éš”ç¬¦ï¼Œé€æ­¥é™çº§

        ç‰¹ç‚¹ï¼š
        - ä¼˜å…ˆä¿æŒæ®µè½å®Œæ•´
        - å…¶æ¬¡ä¿æŒå¥å­å®Œæ•´
        - æœ€åæ‰å­—ç¬¦çº§åˆ†å‰²
        """
        return self._recursive_split_helper(text, self.separators)

    def _recursive_split_helper(
            self,
            text: str,
            separators: List[str],
            start_idx: int = 0
    ) -> List[Chunk]:
        """é€’å½’åˆ†å—è¾…åŠ©å‡½æ•°"""
        chunks = []

        # å¦‚æœæ–‡æœ¬å·²ç»è¶³å¤Ÿå°ï¼Œç›´æ¥è¿”å›
        if len(text) <= self.chunk_size:
            return [Chunk(
                text=text,
                start_idx=start_idx,
                end_idx=start_idx + len(text),
                metadata={'type': 'recursive'}
            )]

        # å°è¯•ä½¿ç”¨å½“å‰åˆ†éš”ç¬¦
        if not separators:
            # æ— åˆ†éš”ç¬¦å¯ç”¨ï¼Œå¼ºåˆ¶åˆ†å‰²
            return self._force_split(text, start_idx)

        separator = separators[0]
        remaining_separators = separators[1:]

        # åˆ†å‰²æ–‡æœ¬
        if separator:
            splits = text.split(separator)
        else:
            # å­—ç¬¦çº§åˆ†å‰²
            splits = list(text)

        # åˆå¹¶å°å—
        current_chunk = ""
        current_start = start_idx

        for i, split in enumerate(splits):
            if not split:
                continue

            # æ·»åŠ åˆ†éš”ç¬¦ï¼ˆé™¤äº†æœ€åä¸€ä¸ªï¼‰
            if separator and i < len(splits) - 1:
                split += separator

            # åˆ¤æ–­æ˜¯å¦éœ€è¦æ–°å»ºå—
            if len(current_chunk) + len(split) > self.chunk_size and current_chunk:
                # å½“å‰å—å·²æ»¡ï¼Œä¿å­˜
                chunks.append(Chunk(
                    text=current_chunk,
                    start_idx=current_start,
                    end_idx=current_start + len(current_chunk),
                    metadata={'type': 'recursive'}
                ))

                # å¼€å§‹æ–°å—ï¼ˆè€ƒè™‘é‡å ï¼‰
                if self.chunk_overlap > 0:
                    overlap_text = current_chunk[-self.chunk_overlap:]
                    current_chunk = overlap_text + split
                    current_start = current_start + len(current_chunk) - self.chunk_overlap - len(split)
                else:
                    current_chunk = split
                    current_start = current_start + len(current_chunk)
            else:
                current_chunk += split

        # æœ€åä¸€ä¸ªå—
        if current_chunk:
            # å¦‚æœå—å¤ªå¤§ï¼Œä½¿ç”¨ä¸‹ä¸€çº§åˆ†éš”ç¬¦é€’å½’åˆ†å‰²
            if len(current_chunk) > self.chunk_size:
                sub_chunks = self._recursive_split_helper(
                    current_chunk,
                    remaining_separators,
                    current_start
                )
                chunks.extend(sub_chunks)
            else:
                chunks.append(Chunk(
                    text=current_chunk,
                    start_idx=current_start,
                    end_idx=current_start + len(current_chunk),
                    metadata={'type': 'recursive'}
                ))

        return chunks

    def _sliding_window_split(self, text: str) -> List[Chunk]:
        """
        æ»‘åŠ¨çª—å£åˆ†å—

        ç‰¹ç‚¹ï¼š
        - é«˜é‡å ç‡
        - é€‚åˆé—®ç­”åœºæ™¯
        - ç¡®ä¿å…³é”®ä¿¡æ¯ä¸ä¸¢å¤±
        """
        chunks = []
        window_size = self.chunk_size
        step_size = self.chunk_size - self.chunk_overlap

        start = 0
        while start < len(text):
            end = min(start + window_size, len(text))
            chunk_text = text[start:end]

            chunk = Chunk(
                text=chunk_text,
                start_idx=start,
                end_idx=end,
                metadata={'type': 'sliding_window'}
            )
            chunks.append(chunk)

            start += step_size

            # å¦‚æœå‰©ä½™æ–‡æœ¬å¾ˆçŸ­ï¼Œç›´æ¥åŠ å…¥æœ€åä¸€ä¸ªå—
            if len(text) - start < step_size:
                break

        return chunks

    def _force_split(self, text: str, start_idx: int) -> List[Chunk]:
        """å¼ºåˆ¶åˆ†å‰²ï¼ˆå­—ç¬¦çº§ï¼‰"""
        chunks = []
        for i in range(0, len(text), self.chunk_size - self.chunk_overlap):
            chunk_text = text[i:i + self.chunk_size]
            chunks.append(Chunk(
                text=chunk_text,
                start_idx=start_idx + i,
                end_idx=start_idx + i + len(chunk_text),
                metadata={'type': 'forced'}
            ))
        return chunks

    def _is_heading(self, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºæ ‡é¢˜"""
        # ç« èŠ‚æ ‡é¢˜æ¨¡å¼
        patterns = [
            r'^ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒ\d]+[ç« èŠ‚æ¡]',
            r'^\d+[\.\s]',
            r'^[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+[\.\ã€]',
        ]

        for pattern in patterns:
            if re.match(pattern, text.strip()):
                return True

        return False


# =========================================
# ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹
# =========================================
"""
from services.document.splitter import DocumentSplitter

# 1. é€’å½’åˆ†å—ï¼ˆæ¨èï¼‰
splitter = DocumentSplitter(chunk_size=500, chunk_overlap=50)
chunks = splitter.split(long_text, method='recursive')

for chunk in chunks:
    print(f"å—{chunk.metadata['chunk_index']}: {chunk.length}å­—ç¬¦")
    print(chunk.text[:100])
    print("---")


# 2. è¯­ä¹‰åˆ†å—
splitter = DocumentSplitter(chunk_size=1000, chunk_overlap=100)
chunks = splitter.split(long_text, method='semantic')


# 3. æ»‘åŠ¨çª—å£ï¼ˆé«˜é‡å ï¼‰
splitter = DocumentSplitter(chunk_size=300, chunk_overlap=150)
chunks = splitter.split(long_text, method='sliding')


# 4. å¸¦å…ƒæ•°æ®
metadata = {
    'doc_id': 'GB50009-2012',
    'source': 'PDF',
    'page': 1
}
chunks = splitter.split(text, method='recursive', metadata=metadata)
"""