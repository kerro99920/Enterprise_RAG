"""
è¿›åº¦åˆ†æAgent
==============

ğŸ“š æ¨¡å—è¯´æ˜ï¼š
- é¡¹ç›®è¿›åº¦å¤šç»´åº¦åˆ†æ
- SPI/EVMæŒ‡æ ‡è®¡ç®—ä¸è¯„ä¼°
- å»¶æœŸä»»åŠ¡è¯†åˆ«ä¸é¢„è­¦
- è¿›åº¦é¢„æµ‹ä¸ä¼˜åŒ–å»ºè®®

ğŸ¯ æ ¸å¿ƒåŠŸèƒ½ï¼š
1. è¿›åº¦æ¦‚è§ˆï¼šé¡¹ç›®æ•´ä½“è¿›åº¦çŠ¶æ€
2. SPIåˆ†æï¼šè¿›åº¦ç»©æ•ˆæŒ‡æ•°è®¡ç®—
3. å»¶æœŸè¯†åˆ«ï¼šå»¶æœŸä»»åŠ¡æ£€æµ‹ä¸åˆ†ç±»
4. å…³é”®è·¯å¾„ï¼šå…³é”®è·¯å¾„ä»»åŠ¡åˆ†æ
5. è¶‹åŠ¿åˆ†æï¼šè¿›åº¦å˜åŒ–è¶‹åŠ¿
6. å®Œå·¥é¢„æµ‹ï¼šé¡¹ç›®å®Œå·¥æ—¶é—´é¢„æµ‹
7. ç“¶é¢ˆè¯†åˆ«ï¼šèµ„æºå’Œè¿›åº¦ç“¶é¢ˆ
8. ä¼˜åŒ–å»ºè®®ï¼šåŸºäºRAGç”Ÿæˆå»ºè®®

ğŸ’¡ ä½¿ç”¨æ–¹å¼ï¼š
    from agents.progress_agent import ProgressAnalysisAgent, get_progress_agent

    agent = get_progress_agent(db)
    result = await agent.analyze_progress("P001")
"""

from __future__ import annotations

import json
from datetime import date, datetime, timedelta
from typing import Any, Dict, List, Optional
from dataclasses import dataclass, field, asdict
from enum import Enum

from sqlalchemy.orm import Session
from loguru import logger

# å¯¼å…¥å·¥å…·æ¨¡å—
from tools.progress_tools import ProgressTools, get_progress_tools
from tools.rag_tool import run_rag

# å¯¼å…¥æ•°æ®æ¨¡å‹
from models.project import AgentWorkflowLog


class ProgressRiskLevel(str, Enum):
    """è¿›åº¦é£é™©ç­‰çº§"""
    CRITICAL = "critical"  # ä¸¥é‡å»¶æœŸ (SPI < 0.75)
    HIGH = "high"  # é«˜é£é™© (SPI 0.75-0.85)
    MEDIUM = "medium"  # ä¸­é£é™© (SPI 0.85-0.95)
    LOW = "low"  # ä½é£é™© (SPI >= 0.95)


class TaskStatus(str, Enum):
    """ä»»åŠ¡çŠ¶æ€"""
    NOT_STARTED = "not_started"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    DELAYED = "delayed"
    SUSPENDED = "suspended"


@dataclass
class ProgressOverview:
    """è¿›åº¦æ¦‚è§ˆ"""
    project_id: str = ""
    project_name: str = ""
    project_manager: str = ""
    start_date: str = ""
    planned_end_date: str = ""
    overall_progress: float = 0.0
    planned_progress: float = 0.0
    variance: float = 0.0
    total_tasks: int = 0
    completed_tasks: int = 0
    in_progress_tasks: int = 0
    delayed_tasks: int = 0
    not_started_tasks: int = 0


@dataclass
class SPIAnalysis:
    """SPIåˆ†æç»“æœ"""
    overall_spi: float = 1.0
    risk_level: str = "low"
    variance_days: int = 0
    earned_value: float = 0.0
    planned_value: float = 0.0
    schedule_status: str = "æ­£å¸¸"


@dataclass
class DelayedTask:
    """å»¶æœŸä»»åŠ¡"""
    task_id: str = ""
    task_name: str = ""
    planned_progress: float = 0.0
    actual_progress: float = 0.0
    spi: float = 1.0
    delay_days: int = 0
    planned_end: str = ""
    is_critical: bool = False
    responsible: str = ""
    delay_reason: str = ""


@dataclass
class CriticalPathTask:
    """å…³é”®è·¯å¾„ä»»åŠ¡"""
    task_id: str = ""
    task_name: str = ""
    planned_start: str = ""
    planned_end: str = ""
    actual_progress: float = 0.0
    spi: float = 1.0
    status: str = ""
    is_delayed: bool = False
    slack_days: int = 0


@dataclass
class ProgressTrend:
    """è¿›åº¦è¶‹åŠ¿"""
    date: str = ""
    planned_progress: float = 0.0
    actual_progress: float = 0.0
    spi: float = 1.0
    variance: float = 0.0


@dataclass
class CompletionPrediction:
    """å®Œå·¥é¢„æµ‹"""
    predicted_end_date: str = ""
    original_end_date: str = ""
    delay_days: int = 0
    confidence: float = 0.0
    method: str = ""
    will_delay: bool = False


@dataclass
class Bottleneck:
    """ç“¶é¢ˆåˆ†æ"""
    bottleneck_type: str = ""
    description: str = ""
    affected_tasks: List[str] = field(default_factory=list)
    impact_level: str = "medium"
    recommendation: str = ""


@dataclass
class ProgressAnalysisResult:
    """è¿›åº¦åˆ†æç»“æœ"""
    project_id: str = ""
    project_name: str = ""
    analysis_date: str = ""
    analysis_period: str = ""

    # è¿›åº¦æ¦‚è§ˆ
    overview: ProgressOverview = field(default_factory=ProgressOverview)

    # SPIåˆ†æ
    spi_analysis: SPIAnalysis = field(default_factory=SPIAnalysis)

    # å»¶æœŸä»»åŠ¡
    delayed_tasks: List[DelayedTask] = field(default_factory=list)
    delayed_count: int = 0
    critical_delayed_count: int = 0

    # å…³é”®è·¯å¾„
    critical_path_tasks: List[CriticalPathTask] = field(default_factory=list)
    critical_path_status: str = "normal"

    # è¿›åº¦è¶‹åŠ¿
    trends: List[ProgressTrend] = field(default_factory=list)
    trend_direction: str = "stable"

    # å®Œå·¥é¢„æµ‹
    prediction: CompletionPrediction = field(default_factory=CompletionPrediction)

    # ç“¶é¢ˆåˆ†æ
    bottlenecks: List[Bottleneck] = field(default_factory=list)

    # èµ„æºé…ç½®
    resource_status: str = "normal"
    parallel_tasks: int = 0

    # å»ºè®®
    suggestions: List[str] = field(default_factory=list)
    ai_insights: List[str] = field(default_factory=list)

    # æ‰§è¡Œä¿¡æ¯
    success: bool = True
    execution_time: float = 0.0
    error: str = ""


class ProgressAnalysisAgent:
    """
    è¿›åº¦åˆ†æAgent

    èŒè´£ï¼š
    - ç¼–æ’è¿›åº¦åˆ†æå·¥å…·
    - å¤šç»´åº¦è¿›åº¦è¯„ä¼°
    - ç”Ÿæˆé¢„è­¦å’Œå»ºè®®
    """

    THRESHOLDS = {
        "spi_critical": 0.75,
        "spi_high": 0.85,
        "spi_medium": 0.95,
        "delayed_tasks_critical": 10,
        "delayed_tasks_high": 5,
        "critical_delayed_warning": 2
    }

    def __init__(self, db: Session):
        """åˆå§‹åŒ–Agent"""
        self.db = db
        self.progress_tools = get_progress_tools(db)
        logger.info("ProgressAnalysisAgent åˆå§‹åŒ–å®Œæˆ")

    async def analyze_progress(
            self,
            project_id: str,
            analysis_days: int = 30,
            include_ai_insights: bool = True
    ) -> Dict[str, Any]:
        """æ‰§è¡Œå…¨é¢è¿›åº¦åˆ†æ"""
        start_time = datetime.now()
        workflow_log = None

        try:
            workflow_log = self._start_workflow(project_id, "progress_analysis")
            logger.info(f"å¼€å§‹é¡¹ç›® {project_id} è¿›åº¦åˆ†æ")

            result = ProgressAnalysisResult(
                project_id=project_id,
                analysis_date=date.today().isoformat(),
                analysis_period=f"æœ€è¿‘{analysis_days}å¤©"
            )

            # Step 1: è·å–é¡¹ç›®æ¦‚è§ˆ
            overview_data = self.progress_tools.get_project_overview(project_id)
            result.overview = self._build_overview(overview_data)
            result.project_name = result.overview.project_name

            # Step 2: SPIåˆ†æ
            status_data = self.progress_tools.get_progress_status(project_id)
            result.spi_analysis = self._build_spi_analysis(status_data)

            # Step 3: å»¶æœŸä»»åŠ¡
            delayed_data = self.progress_tools.get_delayed_tasks(project_id)
            result.delayed_tasks = self._build_delayed_tasks(delayed_data)
            result.delayed_count = len(result.delayed_tasks)
            result.critical_delayed_count = len([t for t in result.delayed_tasks if t.is_critical])

            # Step 4: å…³é”®è·¯å¾„
            critical_data = self.progress_tools.get_critical_path_tasks(project_id)
            result.critical_path_tasks = self._build_critical_path(critical_data)
            result.critical_path_status = self._assess_critical_path_status(result.critical_path_tasks)

            # Step 5: è¶‹åŠ¿åˆ†æ
            trend_data = self.progress_tools.analyze_progress_trend(project_id, days=analysis_days)
            result.trends = self._build_trends(trend_data)
            result.trend_direction = self._determine_trend_direction(result.trends)

            # Step 6: å®Œå·¥é¢„æµ‹
            prediction_data = self.progress_tools.predict_completion_time(project_id)
            result.prediction = self._build_prediction(prediction_data)

            # Step 7: ç“¶é¢ˆè¯†åˆ«
            bottleneck_data = self.progress_tools.identify_bottlenecks(project_id)
            result.bottlenecks = self._build_bottlenecks(bottleneck_data)

            # Step 8: èµ„æºé…ç½®
            resource_data = self.progress_tools.get_resource_allocation(project_id)
            result.resource_status = resource_data.get("load_status", "normal")
            result.parallel_tasks = resource_data.get("parallel_tasks", 0)

            # Step 9: ç”Ÿæˆå»ºè®®
            result.suggestions = self._generate_suggestions(result)

            # Step 10: AIæ´å¯Ÿ
            if include_ai_insights:
                result.ai_insights = await self._generate_ai_insights(result)

            result.success = True
            result.execution_time = (datetime.now() - start_time).total_seconds()

            self._complete_workflow(workflow_log, result, start_time)
            logger.info(f"è¿›åº¦åˆ†æå®Œæˆï¼Œè€—æ—¶: {result.execution_time:.2f}ç§’")

            return asdict(result)

        except Exception as e:
            error_msg = f"è¿›åº¦åˆ†æå¤±è´¥: {str(e)}"
            logger.error(error_msg)
            self._fail_workflow(workflow_log, error_msg)
            return {
                "success": False,
                "project_id": project_id,
                "error": error_msg,
                "execution_time": (datetime.now() - start_time).total_seconds()
            }

    async def quick_progress_check(self, project_id: str) -> Dict[str, Any]:
        """å¿«é€Ÿè¿›åº¦æ£€æŸ¥"""
        try:
            overview = self.progress_tools.get_project_overview(project_id)
            status = self.progress_tools.get_progress_status(project_id)

            spi = status.get("overall_spi", 1)
            delayed_count = overview.get("delayed_tasks", 0)

            if spi < self.THRESHOLDS["spi_critical"] or delayed_count >= self.THRESHOLDS["delayed_tasks_critical"]:
                risk_level = "critical"
            elif spi < self.THRESHOLDS["spi_high"] or delayed_count >= self.THRESHOLDS["delayed_tasks_high"]:
                risk_level = "high"
            elif spi < self.THRESHOLDS["spi_medium"]:
                risk_level = "medium"
            else:
                risk_level = "low"

            alerts = []
            if spi < self.THRESHOLDS["spi_high"]:
                alerts.append(f"SPIåä½: {spi:.2f}")
            if delayed_count >= self.THRESHOLDS["delayed_tasks_high"]:
                alerts.append(f"å»¶æœŸä»»åŠ¡: {delayed_count}ä¸ª")

            return {
                "success": True,
                "project_id": project_id,
                "check_time": datetime.now().isoformat(),
                "overall_progress": overview.get("overall_progress", 0),
                "spi": spi,
                "delayed_tasks": delayed_count,
                "risk_level": risk_level,
                "alerts": alerts
            }

        except Exception as e:
            return {"success": False, "project_id": project_id, "error": str(e)}

    def _build_overview(self, data: Dict) -> ProgressOverview:
        """æ„å»ºè¿›åº¦æ¦‚è§ˆ"""
        return ProgressOverview(
            project_id=data.get("project_id", ""),
            project_name=data.get("project_name", ""),
            project_manager=data.get("project_manager", ""),
            start_date=data.get("start_date", ""),
            planned_end_date=data.get("planned_end_date", ""),
            overall_progress=data.get("overall_progress", 0),
            planned_progress=data.get("planned_progress", 0),
            variance=data.get("overall_progress", 0) - data.get("planned_progress", 0),
            total_tasks=data.get("total_tasks", 0),
            completed_tasks=data.get("completed_tasks", 0),
            in_progress_tasks=data.get("in_progress_tasks", 0),
            delayed_tasks=data.get("delayed_tasks", 0),
            not_started_tasks=data.get("not_started_tasks", 0)
        )

    def _build_spi_analysis(self, data: Dict) -> SPIAnalysis:
        """æ„å»ºSPIåˆ†æ"""
        spi = data.get("overall_spi", 1)
        if spi < self.THRESHOLDS["spi_critical"]:
            risk_level = "critical"
            schedule_status = "ä¸¥é‡æ»å"
        elif spi < self.THRESHOLDS["spi_high"]:
            risk_level = "high"
            schedule_status = "æ˜æ˜¾æ»å"
        elif spi < self.THRESHOLDS["spi_medium"]:
            risk_level = "medium"
            schedule_status = "è½»å¾®æ»å"
        else:
            risk_level = "low"
            schedule_status = "æ­£å¸¸" if spi <= 1.05 else "æå‰"

        return SPIAnalysis(
            overall_spi=spi,
            risk_level=risk_level,
            variance_days=data.get("variance_days", 0),
            earned_value=data.get("earned_value", 0),
            planned_value=data.get("planned_value", 0),
            schedule_status=schedule_status
        )

    def _build_delayed_tasks(self, data: List[Dict]) -> List[DelayedTask]:
        """æ„å»ºå»¶æœŸä»»åŠ¡åˆ—è¡¨"""
        return [DelayedTask(
            task_id=task.get("task_id", ""),
            task_name=task.get("task_name", ""),
            planned_progress=task.get("planned_progress", 0),
            actual_progress=task.get("actual_progress", 0),
            spi=task.get("spi", 1),
            delay_days=task.get("delay_days", 0),
            planned_end=task.get("planned_end", ""),
            is_critical=task.get("is_critical", False),
            responsible=task.get("responsible", ""),
            delay_reason=task.get("delay_reason", "")
        ) for task in data]

    def _build_critical_path(self, data: List[Dict]) -> List[CriticalPathTask]:
        """æ„å»ºå…³é”®è·¯å¾„ä»»åŠ¡"""
        return [CriticalPathTask(
            task_id=task.get("task_id", ""),
            task_name=task.get("task_name", ""),
            planned_start=task.get("planned_start", ""),
            planned_end=task.get("planned_end", ""),
            actual_progress=task.get("actual_progress", 0),
            spi=task.get("spi", 1),
            status=task.get("status", ""),
            is_delayed=task.get("is_delayed", False),
            slack_days=task.get("slack_days", 0)
        ) for task in data]

    def _assess_critical_path_status(self, tasks: List[CriticalPathTask]) -> str:
        """è¯„ä¼°å…³é”®è·¯å¾„çŠ¶æ€"""
        delayed_count = len([t for t in tasks if t.is_delayed])
        if delayed_count >= 3:
            return "critical"
        elif delayed_count >= 1:
            return "warning"
        return "normal"

    def _build_trends(self, data: Dict) -> List[ProgressTrend]:
        """æ„å»ºè¶‹åŠ¿æ•°æ®"""
        updates = data.get("updates", [])
        return [ProgressTrend(
            date=update.get("date", ""),
            planned_progress=update.get("planned_progress", 0),
            actual_progress=update.get("actual_progress", 0),
            spi=update.get("spi", 1),
            variance=update.get("actual_progress", 0) - update.get("planned_progress", 0)
        ) for update in updates]

    def _determine_trend_direction(self, trends: List[ProgressTrend]) -> str:
        """åˆ¤æ–­è¶‹åŠ¿æ–¹å‘"""
        if len(trends) < 2:
            return "stable"
        recent_spis = [t.spi for t in trends[-5:]]
        if len(recent_spis) >= 2:
            if recent_spis[-1] > recent_spis[0] + 0.03:
                return "improving"
            elif recent_spis[-1] < recent_spis[0] - 0.03:
                return "deteriorating"
        return "stable"

    def _build_prediction(self, data: Dict) -> CompletionPrediction:
        """æ„å»ºé¢„æµ‹ç»“æœ"""
        return CompletionPrediction(
            predicted_end_date=data.get("predicted_end_date", ""),
            original_end_date=data.get("original_end_date", ""),
            delay_days=data.get("delay_days", 0),
            confidence=data.get("confidence", 0),
            method=data.get("method", "EVM"),
            will_delay=data.get("will_delay", False)
        )

    def _build_bottlenecks(self, data: Dict) -> List[Bottleneck]:
        """æ„å»ºç“¶é¢ˆåˆ†æ"""
        bottlenecks = data.get("bottlenecks", [])
        return [Bottleneck(
            bottleneck_type=b.get("type", ""),
            description=b.get("description", ""),
            affected_tasks=b.get("affected_tasks", []),
            impact_level=b.get("impact_level", "medium"),
            recommendation=b.get("recommendation", "")
        ) for b in bottlenecks]

    def _generate_suggestions(self, result: ProgressAnalysisResult) -> List[str]:
        """ç”Ÿæˆè¿›åº¦å»ºè®®"""
        suggestions = []

        # åŸºäºSPI
        if result.spi_analysis.risk_level == "critical":
            suggestions.append("ğŸ”´ ç´§æ€¥ï¼šè¿›åº¦ä¸¥é‡æ»åï¼Œå»ºè®®ç«‹å³å¬å¼€è¿›åº¦ä¸“é¡¹ä¼šè®®")
        elif result.spi_analysis.risk_level == "high":
            suggestions.append("ğŸŸ¡ è­¦å‘Šï¼šè¿›åº¦æ˜æ˜¾æ»åï¼Œéœ€è¦åŠ å¼ºç®¡æ§")

        # åŸºäºå…³é”®è·¯å¾„
        if result.critical_path_status == "critical":
            suggestions.append("âš ï¸ å…³é”®è·¯å¾„å¤šä»»åŠ¡å»¶æœŸï¼Œå¯èƒ½å½±å“æ€»å·¥æœŸ")

        # åŸºäºå»¶æœŸä»»åŠ¡
        if result.critical_delayed_count > 0:
            suggestions.append(f"ğŸ“Œ å…³é”®ä»»åŠ¡å»¶æœŸ{result.critical_delayed_count}ä¸ªï¼Œéœ€é‡ç‚¹å…³æ³¨")

        # åŸºäºèµ„æº
        if result.resource_status == "ç´§å¼ ":
            suggestions.append("ğŸ‘¥ èµ„æºè´Ÿè·è¾ƒé‡ï¼Œè€ƒè™‘å¢åŠ äººå‘˜æˆ–è°ƒæ•´è®¡åˆ’")

        if not suggestions:
            suggestions.append("âœ… é¡¹ç›®è¿›åº¦æ­£å¸¸ï¼Œç»§ç»­ä¿æŒ")

        return suggestions

    async def _generate_ai_insights(self, result: ProgressAnalysisResult) -> List[str]:
        """ç”ŸæˆAIæ´å¯Ÿ"""
        try:
            context = f"""
            é¡¹ç›®è¿›åº¦åˆ†æç»“æœï¼š
            - æ•´ä½“è¿›åº¦: {result.overview.overall_progress}%
            - SPI: {result.spi_analysis.overall_spi}
            - å»¶æœŸä»»åŠ¡: {result.delayed_count}ä¸ª
            - å…³é”®ä»»åŠ¡å»¶æœŸ: {result.critical_delayed_count}ä¸ª
            - è¶‹åŠ¿: {result.trend_direction}
            """
            query = "åŸºäºä»¥ä¸Šè¿›åº¦åˆ†æç»“æœï¼Œè¯·æä¾›ä¸“ä¸šçš„è¿›åº¦ç®¡æ§å»ºè®®"
            rag_result = await run_rag(query, context=context)
            if rag_result and "answer" in rag_result:
                insights = rag_result["answer"].split("\n")
                return [i.strip() for i in insights if i.strip()]
            return ["å»ºè®®æŒç»­ç›‘æ§è¿›åº¦æ‰§è¡Œæƒ…å†µ"]
        except Exception as e:
            logger.warning(f"AIæ´å¯Ÿç”Ÿæˆå¤±è´¥: {e}")
            return []

    def _start_workflow(self, project_id: str, workflow_type: str) -> Optional[AgentWorkflowLog]:
        """å¼€å§‹å·¥ä½œæµæ—¥å¿—"""
        try:
            log = AgentWorkflowLog(
                project_id=project_id, workflow_type=workflow_type,
                start_time=datetime.now(), status="running",
                input_params=json.dumps({"project_id": project_id})
            )
            self.db.add(log)
            self.db.commit()
            self.db.refresh(log)
            return log
        except Exception as e:
            logger.warning(f"è®°å½•å·¥ä½œæµå¼€å§‹å¤±è´¥: {e}")
            return None

    def _complete_workflow(self, log: Optional[AgentWorkflowLog], result: Any, start_time: datetime):
        """å®Œæˆå·¥ä½œæµæ—¥å¿—"""
        if log:
            try:
                log.end_time = datetime.now()
                log.status = "completed"
                summary = {
                    "spi": result.spi_analysis.overall_spi if hasattr(result, 'spi_analysis') else 0,
                    "delayed_count": result.delayed_count if hasattr(result, 'delayed_count') else 0
                }
                log.output_result = json.dumps(summary)
                self.db.commit()
            except Exception as e:
                logger.warning(f"è®°å½•å·¥ä½œæµå®Œæˆå¤±è´¥: {e}")

    def _fail_workflow(self, log: Optional[AgentWorkflowLog], error: str):
        """è®°å½•å·¥ä½œæµå¤±è´¥"""
        if log:
            try:
                log.end_time = datetime.now()
                log.status = "failed"
                log.error_message = error[:1000]
                self.db.commit()
            except Exception as e:
                logger.warning(f"è®°å½•å·¥ä½œæµå¤±è´¥çŠ¶æ€å¤±è´¥: {e}")


def get_progress_agent(db: Session) -> ProgressAnalysisAgent:
    """å·¥å‚å‡½æ•°ï¼šåˆ›å»ºè¿›åº¦åˆ†æAgentå®ä¾‹"""
    return ProgressAnalysisAgent(db)